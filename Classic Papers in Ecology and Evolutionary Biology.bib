Automatically generated by Mendeley 1.0.1
Any changes to this file will be lost if it is regenerated by Mendeley.

@incollection{Eldredge1972a,
annote = {Niles Eldredge and Stephen Jay Gould introduced the concept of "punctuated equilibria" as an alternative to the "phyletic gradualism". It's a new picture for interpreting the fossil evidence. Punctuated equibria is characterized by long periods of morphological stability alternated with rapid and episodic events of speciation in isolated subpopulations: "Speciation is a rare and difficult event". Eldredge and Gould extended this idea farther (see Punctuated equilibria: the tempo and mode of evolution reconsidered, Paleobiology, 1977).
        
Since Darwin, new species can arise in only two ways: by the transformation of an entire population from one state to another (phyletic evolution) or by the splitting of the lineage (speciation). The transformation is a slow, progressive, evenly, and gradual process that involves entire large populations over all the ancestral species' geographic range. Darwin considered speciation largely as a sympatric process, proceeding slowly and gradually too. Eldredge and Gould called this process "phyletic gradualism". Under this approach paleontologists should find in the fossil record all the intermediate forms linking ancestor and descendant. Therefore, the morphological discontinuities that they observe are due to imperfections in the fossil record.
        
Punctuated equlibria is based on allopatric speciation in small, peripherally isolated populations. It can explain many gaps in the fossil record because speciation occurs in an isolated area at the periphery of the ancestral species' geographic range by adaptation to local conditions and reproductive isolation. When the descendant species migrates from the peripherally isolated area in which it was developed into its ancestral range, it differs substantially from its ancestor. Therefore, what we observe in the fossil record is a morphological discontinuity: "This alternative picture merely represents the application to the fossil record of the dominant theory of speciation in modern evolutionary thought". Ernst Mayr already anticipated this hypothesis when he developed the concept of biological species.},
author = {Eldredge, N and Gould, SJ},
booktitle = {Models in paleobiology},
file = {::},
pages = {82--115},
title = {{Punctuated equilibria: an alternative to phyletic gradualism}},
url = {http://nileseldredge.com/pdf\_files/Punctuated\_Equilibria\_Eldredge\_Gould\_1972.pdf},
year = {1972}
}
@article{Birch1948a,
annote = {This was the first application of the statistic known as the intrinsic rate of natural increase to an insect population (the weevil Calandra oryzae). It was calculated from experimental data on the age schedule of births and deaths in controlled environments. The study was conducted under the objective of determining the most favorable environments for the storage of grain stockpiled in Australia during the World War II, and hence finding the environments less favorable for the multiplication of the insect pests of stored grain.
        
The measure was based on the demographic parameter developed by Lotka (Elements of physical biology, 1925) for human populations, and developed a few years after the first determination of the intrinsic rate of increase of an animal other than man made by Leslie \& Ranson (The mortality, fertility and rate of natural increase of the vole (Microtus agrestis) as observed in the laboratory, 1940) for the vole Microtus agrestis from age-specific rates of fecundity and mortality determined under laboratory conditions.
        
Birch defined the "intrinsic rate of natural increase" as "the rate of increase per head under specified physical conditions, in an unlimited environment where the effects of increasing density do not need to be considered". The growth of such a population is by definition exponential. This parameter is the "r" in the differential equation for population increase: dN/dt=rN, that is, the difference between the birth-rate and the death-rate in the population. It does not describe the actual rate of increase of a population at a particular point of time but the maximum rate that it can ever maintain over an indefinite period of time "in a population with a stable age distribution". 
        
The method used in the calculations provided a means of determining the extent to which various components enter into the value of the intrinsic rate of natural increase: 1) the life table: the probability at birth of being alive at age x; 2) the fecundity table: the mean number of female offspring produced in a unit of time by a female aged x; and 3) the length of the pre-reproductive stages. One of the results was that the intrinsic rate of natural increase of C. oryzae was determined to a much greater extent by the rate of egg-laying in the first two weeks of life than by the total number of eggs laid in the entire life of 30 weeks.},
author = {Birch, L C},
doi = {10.2307/1605},
file = {::},
issn = {00218790},
journal = {Journal of Animal Ecology},
month = may,
number = {1},
pages = {15--26},
title = {{The intrinsic rate of natural increase of an insect population}},
url = {http://www.jstor.org/stable/1605?origin=crossref},
volume = {17},
year = {1948}
}
@article{Hamilton1964,
annote = {In 1964, biologist William Hamilton described a selective process in which individuals affect kin (kin selection), developed a novel modelling strategy for it (inclusive fitness) and derived a rule to explain it (Hamilton's rule): if the fitness benefits are great enough, then altruism is favored between relatives. With its many successes, the theory became a cornerstone for modern biology.
        
The relatedness originally defined by Hamilton consists in looking at the proportion of genes being transferred from parent to offspring and then infer the relatedness based on the probability that a particular gene that an individual possesses will be found in a relative by their common descend. This gene-level selection assumes that genes are the unit of selection. 
        
Eusocial animals, such as ants, wasps, and bees, form hierarchical social systems with reproductive queens and sterile workers, meaning many individuals take the evolutionary counterintuitive step of sacrificing their own reproduction to care for the offspring of others. The sex determining mechanism of most of these species is called haplodiploidy: fertilized eggs become females and unfertilized eggs males. Hence, males have half the number of chromosomes that a female has, and are haploid. This means that sisters are actually more closely related to each other (r=0.75) than they are to their own offspring, with which their coefficient of relatedness is r=0.5. For four decades kin selection theory, based on the concept of inclusive fitness, has been the major explanation of the evolution of such behavior.
        
Mathematical biologists Martin A. Nowak and Corina E. Tarnita and evolutionary biologist Edward O. Wilson presented recently a controversial work in the journal Nature (The evolution of eusociality, 2010). Their modelling shows that natural selection alone can explain the evolution of eusocial behavior without the need for kin selection theory. Setting aside their arguments against inclusive fitness theory, based upon a misunderstanding of this important concept, the novelty of their paper is that it provides several mechanistic models that explore the conditions under which eusociality might evolve. 
        
Yet, it is necessary to clarify the two major concepts introduced by Hamilton nearly half a century ago. First, inclusive fitness refers to the combination of both direct fitness (i.e. the reproductive success of the individual) and indirect fitness (i.e. an individual controlling or manipulating other reproducers in proximity). Second, kin selection is a cooperative behavior in which an organism works to enhance the reproductive success of a relative. Therefore, it represents only a limited portion of inclusive fitness. More specifically, it is a subset of indirect fitness. },
author = {Hamilton, WD},
file = {::},
journal = {Journal of Theoretical Biology},
pages = {1--16},
title = {{The genetical evolution of social behaviour (I)}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:The+genetic+theory+of+social+behavior\#0},
volume = {7},
year = {1964}
}
@article{Pianka1970b,
annote = {In this short paper, published in Am. Nat. in 1970, Eric R. Pianka reviewed the concepts of r and K selection in order to clarify them and recognize that they did not constitute a true dichotomy but rather merely represented endpoints of a spectrum, what he called "r-K selection continuum". Although he showed that most insects and annual plants are r-selected whereas vertebrates and perennials are comparatively more K-selected, he emphasized that an individual or a population position on the r-K continuum is always changing. 
        
The terms r and K selection ("K" refers to carrying capacity and "r" to the maximal intrinsic rate of natural increase) were coined by MacArthur and Wilson (The theory of island biogeography, 1967). However, as Pianka explained in the first paragraph, Dobzhansky (Evolution in the tropics, 1950) was the first in addressing this question proposing that natural selection acts in a different way in the tropics than in temperate zones: in constant environments lower fecundity and slower development could operate to increase competitive ability (density-dependent selection), whereas in unpredictable environments selection favors high fecundity and rapid development (selection is independent of population density).
        
These two kinds of selection are clearly not restricted to the tropics and temperate zones. We can visualize an r-K continuum, as Pianka explained: "The r-endpoint represents [...] a perfect ecologic vacuum, with no density effects and no competition. Under this situation, the optimal strategy is to put all possible matter and energy into reproduction, with the smallest practicable amount into each individual offspring, and to produce as many total progeny as possible. The K-endpoint [...] density effects are maximal and the environment is saturated with organisms. Competition is keen and the optimal strategy is to channel all available matter and energy into maintenance and the production of a few extremely fit offspring". As the ecological vacuum is filled, selection will shift a population from the r- toward the K-endpoint.
        
Pianka speculated with the importance of the lifespan in generating the dichotomy between insects and annual plants (r-selected) and vertebrate and perennials (K-selected): "To survive, any resident organism with a generation time greater than a year must be adapted to cope with the full range of physical and biotic conditions which prevail at a given locality. An organism which lives less than a year encounters only a portion of the total annual range of conditions [...] Because longer-lived larger organisms are better buffered from environmental vicissitudes, their population sizes do not vary as much as those of smaller, shorter-lived organisms. Furthermore, presumably their competitive relationships are also more predictable and constant. The attainment of a generation time exceeding a year may well be a threshold event in the evolutionary history of a population".},
author = {Pianka, E.R.},
file = {::},
issn = {0003-0147},
journal = {American Naturalist},
number = {940},
pages = {592--597},
publisher = {JSTOR},
title = {{On r-and K-selection}},
url = {http://www.jstor.org/stable/2459020},
volume = {104},
year = {1970}
}
@article{Pimentel1961a,
annote = {In the first half of the past century, empirical studies pointed out the importance of genetic changes as a cause of population fluctuations. But the incorporation of evolutionary dynamics in models of ecological dynamics has been largely ignored. David Pimentel was the first in trying to formalize mathematically the interaction between changes in gene frequency and changes in population size. In this paper he focused analytically on a plant-herbivore system in which prey evolution causes stable or oscillatory predator dynamics, whereas unstable outbreak dynamics is the outcome of the model without evolution.
        
Pimentel and colleagues published the first experimental evidence of evolutionary change directly influencing community dynamics in a series of experiments with houseflies and parasitoid wasps (Space-time structure of the environment and the survival of parasite-host systems, 1963). They demonstrate that evolution towards increased resistance in the host and towards reduced virulence in the parasitoid decisively influenced the community dynamics. Although the techniques for genetic characterization did not exist at the time, they showed that evolution can lead to a dynamical stabilization of a two-species community in laboratory populations.
        
Fussmann and collegues wrote a recent review of theoretical and empirical studies in which evolutionary processes significantly affect the dynamics of populations, communities, and ecosystems (Eco-evolutionary dynamics of communities and ecosystems, 2007). They review instances where rapid evolutionary processes interact with population dynamics. "The few empirical studies on community dynamics that explicitly considered evolutionary processes support the view that evolutionary and ecological dynamics often occur on similar time-scales, and they co-determine the dynamical behaviour of ecological communities." 
        
The study of the interplay between evolutionary and ecological processes has been broadened under the banner of community genetics (see Whitham et. al., Community and ecosystem genetics: a consequence of the extended phenotype, 2003; Neuhauser et. al., Community genetics: expanding the synthesis of ecology and genetics, 2003). The starting point is that changes in genotype frequency results in a change in the phenotypic traits that crucially affect interaction strength among populations, and therefore influence community dynamics.},
author = {Pimentel, David},
file = {::},
journal = {The American Naturalist},
pages = {65--79},
title = {{Population regulation by the genetic feed-back mechanism}},
volume = {95},
year = {1961}
}
@article{Margalef1963,
annote = {In this essay published in Am. Nat. in 1963, Ram\'{o}n Margalef, the greatest Spanish ecologist, pointed out many inspiring ideas about the organization of ecosystems, the historical process of the ecological succession ("simply the exchange of an excess available energy in the present, for a future increase of biomass"), and what he called the "maturity" of an ecosystem: He stated that the structure of a community is linked to its history. The term "maturity" was introduced to take into account the historical process of the ecological succession: "In general, we may speak of a more complex ecosystem as a more mature ecosystem".

        
The structure of an ecosystem can be characterized by considering its elements (individuals and species) and the relationships between them, but also considering matter (biomass) and energy, and their flows. Margalef emphasized the relation between structure and energy flow per unit biomass (primary production/total biomass): "More mature ecosystems, with a richer structure, have a lower primary production per unit biomass. [...] The rate of change [in the ratio primary production/total biomass] is always negative along succession". Maturity can hence be measured as species diversity (if we consider the elements of the ecosystems and their interactions) and as primary production per unit biomass (if we consider biomass and energy).

        
The food chain length was anticipated: "In ecosystems of higher maturity there is a more complete use of food, there is a greater proportion of animals, and energy cascades through a more considerable number of steps". He also connected these ideas with the information theory developed by Shannon in 1948 when he mention the higher efficiency in every relation within the ecosystem as the maturity of the ecosystem increases: "If these relations are considered as communication channels, less noise comes into them". Margalef summarized his ideas in this sentence: "An ecosystem that has a complex structure, rich in information, needs a lower amount of energy for maintaining such structure. [...] This seems to be one of the basic principles of ecology, probably recognized tacitly by most writers, although rarely put in an explicit way". 

        
He predicted dynamical changes in the structure of the ecological networks of interacting species that we studied today: "Any ecosystem not subjected to strong disturbances coming from outside, changes in a progressive and directional way. [...] Links between the elements of an ecosystem can be substituted by other links that work with a higher efficiency, requiring a change in the elements and often an increase in the number of elements and connections". He realized that the predictability of change with time had to be considered, and that more diverse ecosystems have, in general, more predictable future states". This is related with the capacity of an ecosystem to respond to fluctuations: "In a more stable environment, succession proceeds as maturity increases; now we have to expect rhythms that are more regular, more independent of environment and often endogenous. [...] Maturity is self-preserving".

        
Margalef also explored the flows of energy between ecosystems: "An active exploitation by the more mature system may prevent the progressive development of a coupled subsystem, keeping it in a state of low maturity". He compared such a coupling to what happens when a developed country exploits and impedes the economic progress of the undeveloped ones, that is, its maturity. And also to what we can observe in the border between a forest and a open land: "It is expected that there will be more animals in the forest getting food from grassland, than animals in the grassland getting food in the forest".

        
The concepts of r and K selection coined by MacArthur and Wilson (The theory of island biogeography, 1967) were also anticipated by Margalef: "In less mature ecosystems or in less mature trophic levels of any ecosystem, we expect species to be short-lived, easily dispersed, able to colonize with rapidity virgin areas, able to leave numerous offspring and, of course, characterized by high ratio energy flow/biomass. [...] "In more mature ecosystems or in more mature areas of their structure, the selected species are of rather long life, with limited but well protected offspring, and with more restricted possibilities of dispersion accompanied by isolation in small breeding units".},
author = {Margalef, R.},
file = {::},
journal = {American Naturalist},
number = {897},
pages = {357--374},
publisher = {JSTOR},
title = {{On certain unifying principles in ecology}},
url = {http://www.jstor.org/stable/2459227},
volume = {97},
year = {1963}
}
@article{Ehrlich1964,
annote = {Ehrlich and Raven's paper was the first essay explicitly focused on coevolution. It's a detailed description, based on the compilation of an extensive body of information, of the antagonistic interactions between butterflies and the plants used as food by their larvae. They suggested that the elaboration of biochemical defenses by some plants and the adaptive responses of butterflies have played a major role in the evolutionary radiation and diversification of both groups. They wrote: "We hold that plants and phytophagous insects have evolved in part in response to one another". 
        
Although they coined the term coevolution, they didn't define it. Since then, there have been misleading uses of the term, as Daniel H. Janzen pointed out (When is it coevolution? Evolution, 1980). Most of these cases associate the term coevolution to interspecific interactions, such as predator-prey, host-parasite, and mutualism. Is important to keep in mind that interacting species can coevolve, but not necessarily.
        
Janzen's definition of coevolution is restricted to pair-wise interactions: "evolutionary change in a trait of the individuals in one population in response to a trait of the individuals of a second population, followed by an evolutionary response by the second population to the change in the first". When either of both populations in the above definition are represented by more than one species, Janzen refers to the process as "diffuse coevolution". A more general definition of coevolution is given by John N. Thompson: "reciprocal evolutionary change in interacting species driven by natural selection" (The coevolutionary process, 1994).},
author = {Ehrlich, Paul R. and Raven, Peter H.},
file = {::},
journal = {Evolution},
number = {4},
pages = {586--608},
title = {{Butterflies and plants: a study in coevolution}},
volume = {18},
year = {1964}
}
@article{Wright1931a,
annote = {The modern synthesis of population genetics and evolutionary theory was carried out mainly by the contributions of Ronald A. Fisher, Sewall Wright, and John B. S. Haldane, who developed the mathematical theory and explored its ramifications in the 1930's. The models developed assume constant selective values (fitness). Nowadays, it has been demonstrated that these models do not always adequately represent biological reality because the selective values of particular phenotypes appear to change with their frequencies in the population. 
        
In the original models the phenotypic changes depend on both the amount of variation in a population and the intensity of selection. Fisher's formalized in this book this idea in what he described as "The fundamental theory of natural selection". It states that the rate of evolution of a character at any time is proportional to its additive genetic variance, which is the heritable component of a character's genetic basis. The constant of proportionality is the quantitative measure of the intensity of selection. Intuitively, Fisher's theorem implies that individual selection will tend to make a species better adapted to environmental conditions. That is, individual selection always leads to an increase in the average fitness of a population. 
        
Fisher's theorem is not true when there are density or frequency-dependence interactions, linkage among loci, or correlations among characters caused by pleitropic effects of genes. Fisher and Wright showed that frequency- and density-dependent selection at a single locus would cause the mean fitness of a randomly mating population to approach a local maximum. In studies of purely density-dependent selection, several workers have shown that total population size will be maximized as a function of allele frequency at an equilibrium. When there is frequency-dependent selection the situation is more complicated and it is not clear whether natural selection actually maximizes something.
        
In this paper Sewall Wright introduced the concept of "adaptive topography". The environmental conditions determine the actual shape of the surface, and the surface in turn determines the course of evolution of the phenotype. According to Fisher's theorem, evolution will proceed uphill on the surface and stop when a peak is reached. When conditions change, the adaptive surface changes, causing the species to evolve to a new peak. Sewall Wright, who had many disagreements with Fisher (see below), reviewed his book in "The genetical theory of natural selection: a review" (1930) and wrote that it was "certain to take rank as one of the major contributions to the theory of evolution".
        
Wright and Fisher views are different in relation to how environmental changes affect the adaptive topography. Fisher assumed that evolutionary changes follow environmental changes that alter the adaptive topography. Wright, in contrast, argued that evolutionary changes occurred when a species moved to another adaptive peak through the action of other forces, particularly genetic drift. Eldredge and Gould (1972) adopted the Wright view when proposed the punctuated equilibrium theory of evolution. In the punctuational theory, an entire species does not move from one adaptive peak to another (as Wright's says). Instead a species gives rise to a new species which might occupy another adaptive peak. The punctuationalists agree with Wright that individual selection may play a more conservative and less creative role in evolution than Darwin's and Fisher's views.},
author = {Wright, Sewall},
file = {::},
issn = {0016-6731},
journal = {Genetics},
month = mar,
number = {2},
pages = {97--159},
pmid = {17246615},
title = {{Evolution in Mendelian Populations.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1201091\&tool=pmcentrez\&rendertype=abstract},
volume = {16},
year = {1931}
}
@article{MacArthur1966a,
annote = {MacArthur and Pianka's paper together with the Emlen's one (The role of time and energy in food preference), both published in the same issue of Am. Nat. in1966, was the inception of the optimal foraging theory. One of the main predictions of their paper --diets contract when food is abundant and expand when it is scarce-- constitutes one of the major tenets of evolutionary ecology.
        
They developed a graphical model of animal feeding activities based on a trade-off between costs and benefits. Their theoretical predictions are the following: 1) when the prey are abundant, the predator spends all of its time pursuing, catching and eating the prey, so it will choose only those prey items with the highest profitability; and 2) when the prey are scarce, the predator spends all of its time searching, so it will eat every prey item it finds. Therefore, diets should be broad when prey are scarce (long search time) and narrow if prey are abundant (short search time).
        
They also explored the optimal use of patches of habitat in an analogous way as they studied the optimal number of prey in the diet of a predator within a patch. The situation is quite  different in a patchy environment: when the prey is abundant, the searching time between patches is not reduced, so predators with high ratio search/pursuit will not restrict their diets. When the patch size is variable, larger patches should be used in a more specialized way (predators will spend more time within the patches) than smaller patches because travel time between patches is lower.},
author = {MacArthur, R H and Pianka, E R},
file = {::},
journal = {American Naturalist},
number = {916},
pages = {603--609},
title = {{On optimal use of a patchy environment}},
volume = {100},
year = {1966}
}
@article{Hubbs1955,
annote = {This paper, published in 1955, provided a review of the data on natural hybridization in North American freshwater fishes (see the comment written by his son in "This week's citation classic", Current Contents, 1985). It clearly demonstrated the correlation between phylogenic relationship and the capacity to produce hybrids. Carl L. Hubbs showed that natural hybrids were most likely to be found in: i) disturbed environments; ii) localities where one parental species had been introduced; iii) localities where one parental species was rare and the other abundant; and iv) areas of stress where heterosis would enhance abundance.
        
He also noted that hybridization, much more common among closely related species, was inversely associated with fish diversity so that few marine fish hybrids occurred and freshwater fish hybridization was most common in western states.
        
Hubbs also showed, for the firs time, an example of parthenogenetic reproduction in vertebrates: the Amazon molly (Poecilia formosa) is an all-female fish of hybrid origin between Poecilia latipinna and Poecilia mexicana. However, most of the interspecif hybrids the he studied were sterile.},
author = {Hubbs, C.L.},
file = {::},
journal = {Systematic Biology},
number = {1},
pages = {1--20},
publisher = {Oxford University Press},
title = {{Hybridization between fish species in nature}},
url = {http://sysbio.oxfordjournals.org/content/4/1/1.full.pdf},
volume = {4},
year = {1955}
}
@article{Maynard-Smith1973a,
annote = {The logic of animal conflict (I) In this seminal paper John Maynard-Smith and George R. Price introduced the concept of "evolutionarily stable strategy" or ESS. An ESS is defined as "a strategy such that, if most of the members of a population adopt it, there is no mutant strategy that would give higher reproductive fitness". It was the first application of classical game theory to the study of evolution, a reseach line known as "evolutionary game theory", developed in more detail by Maynard-Smith in his book entitled "Evolution and the theory of games" (1982). The idea of ESS was developed independently of the Nash equilibrium developed by Jonh Forbes Nash (Equilibrium points in n-person games, 1950) that it is embedded within the ESS concept.
        
The logic of animal conflict (II) Group selection was the conventional explanation for the absence of serious injuries during a conflict between two animals with offensive weapons: if no ritualized tactics existed, many individuals would be injured, and this would mitigate against the survival of the species. They showed that group selection cannot by itself account for the anatomical and behavioral adaptations for the attenuated conflicts found in so many species. By using the mathematical notation borrowed from classical game theory they found individual selection, strategies advantageous for individuals. 
        
The logic of animal conflict (III) Selection would favor a strategy "hawk", characterized because the individual always continues the contest until he is seriously injured or his opponent retreats, when the payoff penalty for retreating uninjured is the same that for seriously injured.
That would correspond to a species where an individual fights only a single battle in its lifetime, on which its reproductive success entirely depends. The payoff in the evolutionary game is the change in fitness. When the payoff of retreating seriously injured is smaller than for uninjured, individual selection would strongly favor individuals who retreat. This situation represents a species where males have more than one opportunity to gain a mate. 
        
The logic of animal conflict (IV) They not only gave "an explanation of why, in a species with offensive weapons capable of inflicting serious injury, escalated fighting may be rare or absent", but also how "in a contest between opponents who are unable to inflict serious injury, victory goes to the one who is prepared to continue for a longer time". The explanation for the first case was in the framework of "pure strategies", while for the second was in the context of "mixed strategies". These mixed strategies imply either a distribution of different strategies between individuals in a polymorphic population or individuals whose behavior differ from contest to contest.
        
The logic of animal conflict (V) This work was the first step towards a theoretical framework for studying the phenotypic evolution. Thomas L. Vincent and Joel S. Brown have been developing the evolutionary game theory since then. In an early review of the changes that the ESS concept experimented (The evolution of the ESS theory, 1988) they nicely stated: "It is interesting to note, however, that Darwin proposed the theory of evolution by natural selection without knowledge of theoretical population genetics. Is evolution really a game? A game may be defined in terms of four components: rules, players, strategies, and payoffs. The rules of the game determine how the strategies chosen by each individual player affect the payoffs of all players. In an evolutionary game, the individual organisms are the players, their inheritable phenotypes are the strategies, and their fitnesses are the payoffs. The rules of the game are dictated by Nature." },
author = {Maynard-Smith, John and Price, George G.},
file = {::},
journal = {Nature},
pages = {15--18},
title = {{The logic of animal conflict}},
volume = {246},
year = {1973}
}
@incollection{Zuckerkandl1962a,
address = {New York},
annote = {Emile Zuckerkandl and his postdoctoral advisor at Caltech Linus Pauling proposed in 1962 the evolutionary theory of the molecular clock. They used a technique (fingerprinting) to create patterns of the amino acid sequences in hemoglobin molecules of several species. They showed that the number of amino acid differences in those hemoglobin molecules between different lineages changes roughly linearly with time, as estimated from fossil evidence. 
        
They proposed that the comparative-fingerprint method could be used to estimate how long ago any two species deviated from a common ancestor. To do that, the molecular clock must be calibrated using the fossil record because the only thing it can say is that one time period is twice as long as another. Specifically, the authors reached the conclusion that one amino acid would be substituted every eleven to eighteen million years for any given species.
        
The high evolutionary rate estimated from hemoglobin and other proteins was key to develop the neutral theory of molecular evolution by Kimura in 1968. When it was first proposed, the molecular clock was intended to be consistent with natural selection at the molecular level, and only later became associated wih neutralism (Morgan,  "Emile Zuckerkandl, Linus Pauling, and the molecular evolutionary clock", 1998). 
        
The evolutionary theory of the molecular clock assumes a constant rate of evolution over time and over different lineages. This assumption limits the application of molecular clock models, not only because of the largely-known fact that the rate of new mutations depends on the number of generations rather than the number of years, but also because of the recent discoveries made by the field of genomics: nucleotide substitution rates are strongly body size and temperature dependent (the heavier the body weight and the colder the body temperature, the slower the mutation rate), and very heterogeneous over the genome.
        
Despite all these limitations, the molecular clock has become the most useful tool for studying molecular evolution (for more details of its relevance, see: Morgan,  "Emile Zuckerkandl, Linus Pauling, and the molecular evolutionary clock", 1998; Takahata, "Molecular clock: an anti-neo-darwinian legacy", 2007).},
author = {Zuckerkandl, E and Pauling, L},
booktitle = {Horizons in Biochemistry},
editor = {Kasha, M and Pullman, B},
file = {::},
issn = {0022-5010},
keywords = {20th Century,Biological Evolution,Europe,History,Molecular Biology,Molecular Biology: history,United States},
month = jan,
number = {2},
pages = {189--225},
pmid = {11620303},
publisher = {Academic Press},
title = {{Molecular disease, evolution, and genetic heterogeneity}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11620303},
volume = {31},
year = {1962}
}
@article{Brattstrom1965,
annote = {Two decades after Cowles and Bogert demonstrated that reptiles were not cold-blooded but behaviorally thermoregulated largely by the absorption of solar radiation (A preliminary study of the thermal requirements of desert reptiles, 1944), Bayard H. Brattstrom showed that temperate, tropical, alpine, desert, shade-dwelling and burrowing reptiles have a diversity of thermal requirements and abilities to regulate body temperature. This data paper also introduced the notion of physiological control of temperature regulation in some species.
        
Brattstrom did an enormous work measuring body, air, soil, and water temperatures of thousands of reptiles mainly from North America. Combining those data with observations of how the animals behaved, he showed a physiological as well as behavioral control of body temperatures. He also went further when he suggested that the limits of thermal requirements of modern reptiles could indicate past climates (although he was aware of the rates and ranges of thermal acclimation). 
        
His data became the working base for the temperatures reptiles are kept at in captivity and for the thermal limits they can endure in physiological studies.},
author = {Brattstrom, B.H.},
file = {::},
journal = {American Midland Naturalist},
number = {2},
pages = {376--422},
publisher = {JSTOR},
title = {{Body temperatures of reptiles}},
url = {http://www.jstor.org/stable/2423461},
volume = {73},
year = {1965}
}
@article{Hardin1968,
annote = {In a seminal paper, Garrett Hardin argued in 1968 that users of commons are caught in an inevitable process that leads to the destruction of the resources on which they depend. The "rational" user of a common makes demands on a resource until the expected benefits of his or her actions equal the expected costs. Because each user ignores costs imposed on others, individual decisions cumulate to a tragic overuse and the potential destruction of an open-access commons.
        
In England the classic example of the commons is the pasturage set aside for public use, and the "tragedy of the commons" to which Hardin refers was a tragedy of overgrazing and lack of care and fertilization which resulted in erosion and underproduction so destructive that there developed in the late 19th century an enclosure movement. Hardin applies this social institution to other environmental objects such as water, atmosphere, and living space.
        
The cause of this tragedy is exposed by a very simple mathematical model, utilizing the concept of utility drawn from economics. Allowing the utilities to range between a positive value of 1 and a negative value of 1, we may ask, as did the individual English herdsman, what is the utility to me of adding one more animal to my herd that grazes on the commons? His answer is that the positive utility is near 1 and the negative utility is only a fraction of minus 1 since the effects of overgrazing is shared by all the herdsmen. Adding together the component partial utilities, the herdsman concludes that it is rational for him to add another animal to his herd; then another, and so on. The tragedy to which Hardin refers develops because the same rational conclusion is reached by each and every herdsman sharing the commons.
        
To avoid the tragedy Hardin argued that solutions must be imposed on users by external authorities. Today, the conditions most likely to favor sustainable uses of common-pool resources are still under research. Some of the most difficult challenges concern the management of large-scale resources that depend on international cooperation, such as fresh water in international basins or large marine ecosystems (Ostrom et al., Revisiting the commons: local lessons, global challenges, 1999). Will voluntarism save the whales and keep the skies unpolluted? At the end of his paper Hardin argued: "The most important aspect of necessity that we must now recognize, is the necessity of abandoning the commons in breedings. No technical solution can rescue us from the misery of overpopulation. Freedom to breed will bring ruin to all".},
author = {Hardin, Garret},
file = {::},
journal = {Science},
number = {162},
pages = {1243--1248},
publisher = {ME Sharpe Inc},
title = {{The tragedy of the commons}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=DfLEt7HvbtYC\&amp;oi=fnd\&amp;pg=PA173\&amp;dq=The+tragedy+of+the+commons\&amp;ots=Ngw-NFPgdf\&amp;sig=Qj96hRFY78mP32jf3f6nnQF3E8M},
year = {1968}
}
@article{Huffaker1958a,
annote = {This paper is the second covering a series of experiments designed by the entomologist Carl B. Huffaker to "shed light on the fundamental nature of predator-prey interations" and to "stablish an ecosystem in which a predator and a prey species could continue living together so that the phenomena associated with their interactions could be studied in detail".
        
In 1934 G. Gause's experiments with Dinidium and Paramecium as predator and prey, respectively, showed the tendency toward extinction among predator-prey populations in the absence of immigration into the depopulated areas or without the existence of prey refuges restrictive to the predators (The struggle for existence, 1934). Huffaker's work expanded Gause's experiments introducing habitat heterogeneity. He suggested that in "a sufficiently natural environment" coexistence is possible without the Gause's conditions. By "a sufficiently natural environment" he meant a heterogeneous habitat.
        
He designed an experiment using oranges as food for a mite species (another mite species was used as a predator) and varying the spatial position and the amount of accessible orange peel by interspersing the oranges among waxed rubber balls (introducing patchiness). On a single orange, the predator invariably exterminated the prey and then itself by starvation. But as the complexity of the spatial scenario increased making "less likely the predators' contact with the prey at all positions at once" the coexistence was possible and the predator-prey interaction continued for three cycles of population fluctuation.
        
Understanding how spatial heterogeneity and the varying dispersal ability of each species affect long-term population dynamics, Huffaker's original motivation, is still an active field of research today. Recently, Ilkka Hanski has been awarded the Crafoord Prize in Biosciences 2011 "for his pioneering studies on how spatial variation affects the dynamics of animal and plant populations". Congratulations!
      },
author = {Huffaker, C.B.},
file = {::},
journal = {Hilgardia},
number = {14},
pages = {795--835},
publisher = {Univ. of Calif.},
title = {{Experimental studies on predation: dispersion factors and predator-prey oscillations}},
url = {http://faculty.washington.edu/kerrb/Huffaker1958.pdf},
volume = {27},
year = {1958}
}
@book{Fisher1930a,
annote = {The modern synthesis of population genetics and evolutionary theory was carried out mainly by the contributions of Ronald A. Fisher, Sewall Wright, and John B. S. Haldane, who developed the mathematical theory and explored its ramifications in the 1930's. The models developed assume constant selective values (fitness). Nowadays, it has been demonstrated that these models do not always adequately represent biological reality because the selective values of particular phenotypes appear to change with their frequencies in the population. 
        
In the original models the phenotypic changes depend on both the amount of variation in a population and the intensity of selection. Fisher's formalized in this book this idea in what he described as "The fundamental theory of natural selection". It states that the rate of evolution of a character at any time is proportional to its additive genetic variance, which is the heritable component of a character's genetic basis. The constant of proportionality is the quantitative measure of the intensity of selection. Intuitively, Fisher's theorem implies that individual selection will tend to make a species better adapted to environmental conditions. That is, individual selection always leads to an increase in the average fitness of a population. 
        
Fisher's theorem is not true when there are density or frequency-dependence interactions, linkage among loci, or correlations among characters caused by pleitropic effects of genes. Fisher and Wright showed that frequency- and density-dependent selection at a single locus would cause the mean fitness of a randomly mating population to approach a local maximum. In studies of purely density-dependent selection, several workers have shown that total population size will be maximized as a function of allele frequency at an equilibrium. When there is frequency-dependent selection the situation is more complicated and it is not clear whether natural selection actually maximizes something.
        
In this paper Sewall Wright introduced the concept of "adaptive topography". The environmental conditions determine the actual shape of the surface, and the surface in turn determines the course of evolution of the phenotype. According to Fisher's theorem, evolution will proceed uphill on the surface and stop when a peak is reached. When conditions change, the adaptive surface changes, causing the species to evolve to a new peak. Sewall Wright, who had many disagreements with Fisher (see below), reviewed his book in "The genetical theory of natural selection: a review" (1930) and wrote that it was "certain to take rank as one of the major contributions to the theory of evolution".
        
Wright and Fisher views are different in relation to how environmental changes affect the adaptive topography. Fisher assumed that evolutionary changes follow environmental changes that alter the adaptive topography. Wright, in contrast, argued that evolutionary changes occurred when a species moved to another adaptive peak through the action of other forces, particularly genetic drift. Eldredge and Gould (1972) adopted the Wright view when proposed the punctuated equilibrium theory of evolution. In the punctuational theory, an entire species does not move from one adaptive peak to another (as Wright's says). Instead a species gives rise to a new species which might occupy another adaptive peak. The punctuationalists agree with Wright that individual selection may play a more conservative and less creative role in evolution than Darwin's and Fisher's views.},
author = {Fisher, R. A.},
booktitle = {Genetics},
file = {::},
issn = {0016-6731},
keywords = {20th Century,England,Genetic,History,Models,Selection},
month = apr,
number = {4},
pmid = {10747041},
title = {{The genetical theory of natural selection.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1461012\&tool=pmcentrez\&rendertype=abstract},
volume = {154},
year = {1930}
}
@article{Kauffman1969,
abstract = {Proto-organismsprobably were randomly aggregatednets of chemical reactions.The hypothesisthat contemporary organisms alsorandomly are constructed molecular automata is examined by modeling the geneas a binary (on-off) device and studying the behavior of large, randomly con- structed nets of these binary “genes”. The results suggestthat, if each “gene” is directly affectedby two or three other “genes”, then suchrandom nets: behave with great order and stability; undergo behavior cycles whoselength predicts cell replication time asa function of the number of genes cell; possess per different modesof behavior whosenumber per net predictsroughly the number of cell types in an organismas a function of its number of genes; and under the stimulus of noise are capable of differentiating directly from any mode of behavior to at most a few other modesof behavior. Cellular differentation is modeledas a Markov chain amongthe modesof behavior of a geneticnet. The possibility of a general theory of metabolic behavior is suggested},
annote = {Stuart Kauffman is a theoretical biologist who has been thinking about genetic regulatory networks and their role in constraining evolution for over forty years, becoming a legendary figure in complex systems and one of its big thinkers. This paper is the first attempt to study simplified computer models of genetic regulatory networks. His model was called "Random Boolean Networks".  
        
A Random Boolean Network consists of a set of nodes ("genes") and directional links between the nodes ("gene A regulates gene B" is represented by node A linking to node B). Starting from a random initial state, and iterated over a series of time steps, the nodes in the Random Boolean Network change state in random ways for a while (at each time step each node can be in either state "on" or state "off"), and finally settle down to either a fixed point (all nodes' states remain fixed) or an oscillation (the state of the whole network oscillates with some small period). Kauffman found that the typical final behavior is determined by both the number of nodes in the network and each node's number of incoming links. 
        
Since the Random Boolean Network have a finite number of nodes N, there are only a finite number of possible global states 2\^{}N, so if the network is iterated for long enough it will repeat one of the global states it has already been in, and hence cycle through the next series of states until it repeats that global state again (see the excellent book by Melanie Mitchell entitled "Complexity: a guide tour", 2009). When the number of incoming links to each node is two, he estimated that the average number of different global states was approximately equal to the square root of the number of nodes. Each global state or attractor is a pattern over time of "gene expression". Kauffman proposed that an attractor in his network represents a cell type in an organism's body.
        
Kauffman's model predicted not only the number of cell types in humans (although incorrectly), but also cell replication time as a function of the number of genes per cell. His most important point about living systems is that natural selection is in principle not necessary to create a complex creature (an idea discussed at length in Kauffman's book, The origins of order, 1993). Once a network structure becomes sufficiently complex --that is, has a large number of nodes controlling other nodes-- complex and "self-organized" behavior will emerge. He wrote: "Most of the beautiful order seen in ontogeny is spontaneous, a natural expression of the stunning self-organization that abounds in very complex regulatory networks. We appear to have been profoundly wrong. Order, vas and generative, arises naturally" (Kauffman, At home in the universe, 1995).},
author = {Kauffman, S a},
file = {::},
issn = {0022-5193},
journal = {Journal of Theoretical Biology},
month = mar,
number = {3},
pages = {437--467},
pmid = {5803332},
title = {{Metabolic stability and epigenesis in randomly constructed genetic nets}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/5803332},
volume = {22},
year = {1969}
}
@article{McNab1963,
abstract = {All animals are limited in the extent of their daily wanderings. This is notably true of mammals, for which many estimates of home range exist. It is obvious that the size of a mammal will greatly affect the maximumarea that can be covered and, therefore, will influence the size of the home range. But body size has another, independent influence: larger species must collect more energy to supply their requirements than small species. Generally, a large energy demand will necessitate a large area for food gathering, unless the food exists in superabundance. Many other considera- tions may also alter the size of the home range (Brown, 1962), but the ob- ject of this paper is to examine only the relation between the size of home range and body size, since body size would appear at first glance to be the most important factor in the determinationof home range size.},
annote = {Brian K. McNab wrote this paper in 1963 as a first attempt to quantify the relationship between home range area and body size in mammals, bringing the concept of scaling (i.e., the correlation of quantitative data on an animal with its body size) to ecology. 
        
He showed that the home range of a mammal is proportional to the species' body mass raised to a power b, and that this relation was parallel to that found between the basal rate of metabolism and body size (for which the power b is 0.75). Much of the residual variation in home range size around the mean curve fitted to mass was associated with food habits: home range was large in species that are carnivores and seedeaters ("hunters") and small in species that graze or browse ("croppers"). Therefore, rate of energy expenditure and the ecological factors influencing energy availability have a significant impact on home range size in mammals.
        
McNab concluded that the size of the home range "is determined, mainly, by the amount of energy expended by the species". However, a causal relationship cannot be established from this study. As the author himself said to "This week's citation classic" (Current Contents, 1989): "Aside from the technical question whether the original analysis was, or was not, in some sense "correct", the ideas contained in this paper helped to bring to the attention of ecologists that many aspects of the physiology and ecology of animals can be described as a power function of body mass and that body size is one of the most important characteristics of an animal, an idea that gains prominence with the passage of time".},
author = {McNab, Brian K},
file = {::},
journal = {American Naturalist},
number = {894},
pages = {133--140},
title = {{Bioenergetics and the determination of home range size}},
volume = {97},
year = {1963}
}
@article{Brown1956a,
annote = {Brown and Wilson introduced the term "character displacement" to describe that species will evolve to avoid competition by using different resources. Their point was: if populations of closely related species are different where they occur together, species occurring apart in isolation do not have to be different. "Character displacement is the situation in which, when two species of animals overlap geographically, the differences between them are accentuated in the zone of sympatry and weakened or lost entirely in the parts of their ranges outside this zone. The characters involved in this dual divergence-convergence pattern may be morphological, ecological, behavioral, or physiological". 
        
The idea that populations in sympatry and allopatry represent a natural experiment, allowing the conclusion that differences can be attributed to the presence or absence of the other species was questioned later. Other factors, like habitat differences can explain the pattern. If the habitats of the sympatric and allopatric species are sufficiently similar than the situation can be viewed as a natural experiment, then the question arises of why the species are ever allopatric (see Grant, Convergent and divergent character displacement, 1972). 
        
Slatkin (Models of coevolution: their use and abuse, 1983) reviewed the mathematical models in the study of ecological character displacement and he concluded that character displacement is not the inevitable outcome of competition between species. "Instead, it depends on the balance between two forces, the force of competition between species tending to displace the mean values of the character and the force from the edges of the resource distribution tending to drive the mean values together. The relative strengths of the forces depend on the assumptions of the model and not in an obvious way".
        
Grant (1972), Arthur (The evolutionary consequences of interspecific competition, 1982) and others suggested the following criteria for demonstrating the ocurrence of character displacement (see Schluter and McPhail, Ecological character displacement and speciation in sticklebacks, 1992): (1) chance should be ruled out as an explanation for the pattern; (2) the phenotypic differences between populations in sympatry and allopatry should have a genetic basis; (3) differences between sympatric species must have evolved in situ; (4) morphological differences should reflect differences in resource use; (5) sites in sympatry and allopatry should not differ greatly in food, climate, or other environmental features affecting the phenotype; and (6) resources are limiting and interspecific competition for these resources is a function of character similarity. 
        
Character displacement was viewed as an important force in structuring ecological communities. During the late 1970s and early 1980s, however, the role of competition and character displacement in structuring communities was questioned and its importance greatly downgraded (Losos, Ecological character displacement and the study of adaptation, 2000).},
author = {Brown, William L. and Wilson, E. O.},
file = {::},
journal = {Systematic Zoology},
number = {2},
pages = {49--65},
title = {{Character displacement}},
url = {http://sysbio.oxfordjournals.org/content/5/2/49.full.pdf},
volume = {5},
year = {1956}
}
@article{VanValen1973,
annote = {The evolutionary biologist Leigh Van Valen introduced in this paper the Red Queen's Hypothesis to capture the idea that there is a constant arms race between coevolving antagonistic species. Its name is a reference to the Red Queen's race in Lewis Carroll's "Alice Through the Looking Glass", in which the chess board moves such that Alice must continue running just to stay in the same place: "Now here, you see, it takes all the running you can do to keep in the same place". Continuous development is needed for an evolutionary system just in order to maintain its fitness in relation to the systems it is coevolving with.
        
The focus of the paper was the statement of a "new evolutionary law", or "the law of extinction". Based on the study of different extinct and living taxa, he stated that the length of a species' existence says nothing about its chances of dying off. He defined this law as: "the effective environment of the members of any homogeneous group of organisms deteriorates at a stochastically constant rate". In this formulation, the "effective environment of any organism is its adaptive zone plus the effects of any other organisms within that adaptive zone". He also defined it as: "the extinction in any adaptive zone occurs at a stochastically constant rate".
        
Some of the irregularities in this trend were explained using the results of MacArthur and Wilson work (The theory of island biogeography, 1967). That is, "the extinction rate depends on the area inhabited by the taxa: species and higher taxa occupying smaller areas have an expected rate of extinction greater than that of more widespread taxa". Another explanation was that genera or families with fewer species have a higher probability of extinction because the more diversified the taxonomic group the higher the probability of survival of the entire group.
        
He stated: "The Red Queen's Hypothesis is a sufficient explanation of the law of extinction but not one that is yet derivable with confidence from lower-level knowledge of the causes of individual extinctions and the nature of species interactions". He also envisioned "an adaptive landscape in a resource space", in which the amount of resources is fixed and "if one peak is diminished there must be an equal total increase elsewhere, in one related peak or more uniformly. Similarly, increase in a peak results in an equal decrease elsewhere". This landscape changes continuously because "species displace each other from areas of the adaptive surface", and because the distribution of resources within the landscape changes.
        
Van Valen realized the importance of game theory in undertanding the evolutionary process: "Which adversary is most important for a species may vary from time to time, and for some or even most species no one adversary may ever be paramount. Furthermore, no species can ever win, and new adversaries grinningly replace the losers. This is the direction of generalization of game theory which I think has not been explored". Note the relevance of his words in the last paragraph: "From this overlook we see dynamic equilibria on an immense scale, determining much of the course of evolution by their self-perpetuating fluctuations. This is a novel way of looking at the world, one with which I am not yet comfortable. But I have not yet found evidence against it, and it does make visible new paths and it may even approach reality".},
author = {{Van Valen}, Leigh},
file = {::},
journal = {Evolutionary Theory},
number = {1},
pages = {1--30},
title = {{A new evolutionary law}},
volume = {1},
year = {1973}
}
@article{Nei1975a,
annote = {The genetic variability of a population is generally measured in terms of average heterozygosity. When population size is suddenly reduced, the average heterozygosity per neutral locus is expected to decline. Nei et al. asked the following: how quickly is the original level of heterozygosity attained when population size increases again? They introduced a mathematical formula for describing the average heterozygosity when population size changes. 
        
They also studied, by simulation, the loss of alleles due to a bottleneck effect: "if the number of alleles per locus decreases after a population goes through a bottleneck, the adaptability of the population may be limited even if the average heterozygosity remains fairly high".
        
They showed that 1) "the amount of reduction in heterozygosity due to the bottleneck effect depends not only on the bottleneck size but also on the rate of population growth after going through the bottleneck"; and 2) "the loss of alleles largely depends on the bottleneck size". In relation to these results, they found that the number of alleles per locus is reduced more drastically than the average heterozygosity. "This difference occurs because a bottleneck eliminates very low frequency alleles, while the remaining alleles may exist in intermediate gene frequencies [...], contributing to heterozygosity considerably". 
        
As Nei himself said for Current Contents in 1988, "Many authors cited it [the paper] because it provided a theoretical basis for studying speciation, the biology of colonizing species, and the fate of endangered species". },
author = {Nei, M and Maruyama, T and Chakraborty, R},
file = {::},
journal = {Evolution},
number = {1},
pages = {1--10},
title = {{The bottleneck effect and genetic variability in populations}},
url = {http://www.jstor.org/stable/2407137},
volume = {29},
year = {1975}
}
@article{Paine1966a,
abstract = {It is suggested that local animal species diversity is related to the number of predators in the system and their efficiency in preventing single species from monopolizing some important, limiting, requisite. In the marine rocky intertidal this requisite usually is space. Where predators capable of preventing monopolies are missing, or are experimentally removed, the systems become less diverse. On a local scale, no relationship between latitude (10⚬ to 49⚬ N.) and diversity was found. On a geographic scale, an increased stability of annual production may lead to an increased capacity for systems to support higher-level carnivores. Hence tropical, or other, ecosystems are more diverse, and are characterized by disproportionately more carnivores.},
annote = {The term "keystone species" was first introduced by Robert T. Paine in 1966, when he was studying a community of organisms that inhabited the intertidal zone along Washington's Pacific coast. Paine found that one species, the carnivorous starfish Pisaster ochracceus, played a key role in maintaining the balance of all other species in the community. He observed that if Pisaster ochracceus was removed from the community, the populations of two mussel species within the community grew unchecked. Without a predator to control their numbers, the mussels soon took over the community and led to local extinctions of benthic invertebrates and algae, reducing greatly the community's diversity. Although the term was originally applied to a predator species, it has recently been extended to include also prey species.
        
Paine's hypothesis was stated as: "Local species diversity is directly related to the efficiency with which predators prevent the monopolization of the major environment requisites by one species". His conclusion: "Where predators capable of preventing monopolies are missing, or are experimentally removed, the systems become less diverse", had important implications for the stability-complexity debate: "In the absence of a complicating factor (predation), there is a "winner" in the competition for space, and the local system tends toward simplicity. Predation [...] tends to increase local diversity".
        
The identification of keystone species has become a popular target in conservation efforts: protecting important species stabilizes an entire community. But the problem is how to define and quantify species "importance" in an ecosystem or community. Recent advances in network theory applied to the study of food webs, plant-animal mutualistic networks and host-parasite interactions, provide us insight about the structural and dynamic role of species in a community. Coextinction cascades and changes in species abundances caused by the removal of one species could be used as indicators of the importance of a species within a community. The identity of these keystone species could change within the same community depending on the structure of the network of interactions.},
author = {Paine, Robert T.},
file = {::},
journal = {The American Naturalist},
number = {910},
pages = {65 -- 75},
title = {{Food web complexity and species diversity}},
url = {http://www.jstor.org/stable/2459379},
volume = {100},
year = {1966}
}
@article{Dayton1971a,
annote = {Paul K. Dayton's studies extended his advisor's paper (Paine, Food web complexity and species diversity, 1966) by demonstrating, using field experimentation, that different perturbations structure the intertidal community. This long paper was based on his Ph.D. dissertation, and I brought it to light because one of its major conclusions was that relatively few species have disproportionately important selective influences on most of the other species. That was the inception of the term "foundation species" introduced one year later (Dayton, Toward an understanding of community resilience and the potential effects of enrichments to the benthos at McMurdo Sound, Antarctica, 1972).
        
Following Dayton (1972), a foundation species is "a single species that defines much of the structure of a community by creating locally stable conditions for other species, and by modulating and stabilizing fundamental ecosystem processes." The loss of foundation species changes the local environment on which a variety of other species depend and disrupts fundamental ecosystem processes, including rates of decomposition, nutrient fluxes, carbon sequestration, and energy flow (see Ellison et al., Loss of foundation species: consequences for the structure and dynamics of forested ecosystems, 2005).
        
Other definitions related to the concept of foundation species are: 1)) core species, that are locally abundant and regionally commmon (Hanski, Dynamics of regional distribution: the core and satellite species hypothesis, 1982); 2) dominant species, that competitively exclude subordinate species by garnering a disproportionate share of resources and contributing most to productivity (Grime, Dominant and subordinate components of plant communities: implications for succession, stability and diversity, 1984); 3) keystone predators, that preferentially consume dominant competitors and enhance local biodiversity by preventing exclusion of weaker competitors (Paine, Food web complexity and species diversity, 1996); 4) keystone species, (Holling's extended keystone hypothesis) that all terrestrial ecosystems are controlled and organized by small set of keystone species (Holling, Cross-scale morphology, geometry, and dynamics of ecosystems, 1982); 5) structural species, that create physical structures of environments, produce variability in physical conditions, provide resources, and create habitat for interstitial species (Huston, Biological diversity: the coexistence of species on changing landscapes, 1994); and 6) ecosystems engineers, that cause physical state changes in biotic or abiotic materials and modulate availability of resources to other species (Jones et al., Organisms as ecosystems engineers, 1994).  
        
There has been considerable debate in the ecological literature about whether the requirements of single species should serve as the basis for defining conservation requirements. These single-based approaches use different definitions of species as a shorcut to monitor or solve conservation problems.
        
The most commonly used terms are: 1) umbrella species, whose requirements for persistence are believed to encapsulate those of a significant number of other species across a wide array of taxonomic groups and in functioning natural systems (Murphy \& Wilcox, Butterfly diversity in natural habitat fragments: a test of the validity of vertebrate-based management, 1986); 2) indicator species, that reflect the quality and changes in environmental conditions as well as aspects of community composition (Landres et al., Ecological uses of vertebrate indicator species: a critique, 1988); and 3) flagship species, charismatic large mammals and birds used as vehicles for conveying the entire issue of conservation to the public (Mittermeier, Primate diversity and the tropical forest, 1986). },
author = {Dayton, Paul K},
file = {::},
journal = {Ecological Monographs},
number = {4},
pages = {351--389},
title = {{Competition, disturbance, and community organization: the provision and subsequent utilization of space in a rocky intertidal community}},
url = {http://www.esajournals.org/doi/abs/10.2307/1948498},
volume = {41},
year = {1971}
}
@article{Mode1958,
abstract = {A mathematical model of a host-pathogen system was presented and a theory of the evolutionary significance of the genetic systems uncovered by the work of Briggs and Flor was proposed. It was suggested that these genetic systems uncovered by present day genetic studies are the relics of ancient systems of balanced polymorphism, stemming from the time wheat, barley, and flax reproduced by outbreeding. It was further suggested that a state of dual balanced polymorphism was a necessary condition for the co-evolution of obligate parasites and their hosts.},
annote = {This paper describes the first mathematical model of coevolution. It was developed to explore the coevolutionary dynamics of polymorphism in plants and pathogens. Mode’s model opened the development of what has been called “gene-for-gene” models: any gene in the host for resistance acts if an only if there is a corresponding gene in the pathogen for avirulence.
        
In gene-for-gene models host resistance and pathogen infectivity have associated costs that increase with the level of investment in defense or attack. In contrast, in matching-allele-models there is no differential cost in the expression of alternative alleles (see Agrawal \& Lively, “Infection genetics: gene-for-gene versus matching-alleles models an all points in between”, 2002). Such costs of resistance have long been an important part of the theory of why defense genes do not always become rapidly fixed within populations.
        
Mode ends up the paper suggesting that: “these genetic systems uncovered by present day genetic studies are the relics of ancient systems of balanced polymorphism and that a state of dual balanced polymorphism was a necessary condition for the co-evolution of obligate parasites and their hosts.”
        
Although it is usually thought that Ehrlich \& Raven coined the term coevolution (“Butterflies and plants: a study in coevolution”, 1964), Charles Mode was very aware of what coevolution means: “The genetic system of the host and parasite, therefore, have very likely been established in response to two types of opposing selection pressures, namely, the selection pressure exerted on the host by the parasite, and the selection pressure exerted on the parasite by the host.”
        
After formulating the three basic questions that arise from the genetic system uncovered by previous work, Mode makes an interesting point that we should not forget when dealing with mathematical modeling: “These questions will be considered in turn, but first it is necessary to digress for a moment and discuss some biology of the organisms in question, since a biological understanding of the situation is essential to mathematical arguments that follow”.},
author = {Mode, C.J.},
file = {::},
journal = {Evolution},
number = {2},
pages = {158--165},
publisher = {JSTOR},
title = {{A mathematical model for the co-evolution of obligate parasites and their hosts}},
url = {http://www.jstor.org/stable/2406026},
volume = {12},
year = {1958}
}
@article{kimura1968evolutionary,
annote = {In 1968 Motoo Kimura argued that most mutations in the genome of mammals are neutral, they have no effect on their phenotypes. By using the rate of aminoacids substitution from comparative studies of some proteins (one substitution in a polypeptide chain of 100 aminoacids every 28 million years), he calculated that, on average, one base pair is substituted in a population every two years. This very high rate of nucleotid substitution can only be tolerated by assuming that most mutations produced by nucleotid replacement are neutral or nearly neutral to natural selection. His proposal, controversial at the time, is known as the "neutral theory of molecular evolution" (see his book published in 1983 under the same title).
        
In the last paragraph of his paper he remarked: "Finally, if my chief conclusion is correct, and if the neutral or nearly neutral mutation is produced in each generation at a much higher rate than has been considered before, then we must recognize the great importance of random genetic drift due to finite population number in forming the genetic structure of biological populations". His theory attributes a large role to genetic drift acting on neutral alleles arising typically through mutations of a single nucleotid within the sequence of a gene. These new alleles may be lost or become more common and fixed in the population by the sampling process. This assertion initiated a vigorous debate regarding the relative importance of genetic drift compared with natural selection. But we shouldn't forget that Kimura claimed that genetic changes, not necessarily changes in phenotypes, are the ones mostly caused by genetic drift. 
        
Nowadays it seems clear that, at least at molecular level, neutrality is the rule rather than the exception. In order to study phenotypic evolution one could argue that neutral mutations can be ruled out. But doing that we would assume that the effect of a mutation on the phenotype is independent on the effect of the other genes in the genome. As Ernst Mayr said, natural selection acts on the genome as a whole rather than on a particular gene. The consequences of a mutation depend on the rest of the genome: the same mutation can be neutral for an individual with a given genome, and potentially adaptive for an individual with a different genome. This misconception of how genes work was responsible of the neutralist-selectionist controversy. 
        
The concept of neutral networks of genotypes inspired by John Maynard Smith (Natural selection and the concept of a protein space, 1970) and developed by Peter Schuster and collaborators (From sequences to shapes and back: a case study in RNA secondary structures, 1994) can help reconcile the tension. The assertion by Andreas Wagner: "Neutral mutations prepare the ground for later evolutionary innovation" (Neutralism and selectionism: a network-based reconciliation, 2008) points to the right direction. },
author = {Kimura, M.},
file = {::},
journal = {Nature},
number = {5129},
pages = {624--626},
title = {{Evolutionary rate at the molecular level}},
url = {http://www.eebweb.arizona.edu/Courses/Ecol426\_526/Kimura\_1968.pdf},
volume = {217},
year = {1968}
}
@article{Shannon1948,
annote = {Claude E. Shannon developed the information theory in a long paper published in 1948. He introduced a measure of quantity of information: -sum(p\_i * log2(p\_i)). That is, the capacity of a channel to transmit information, given by the number of different messages that could have been sent. The theory was, in the early days, not concerned with meaning, but only with quantity of information: as Weaver put it: "this word 'information' in communication theory relates not so much to what you do say, as to what you could say" (Shannon and Weaver, "The mathematical theory of communication", 1949).
        
The average number of bits needed for storage or communication is the definition of entropy in statistical mechanics (by Boltzmann). Entropy quantifies the uncertainty involved in predicting the value of a random variable. A bit is a binary digit and has two possible values (0 or 1). Two bits can distinguish four items (00, 01, 10, and 11). Therefore, we can distinguish n items with log2(n) bits. If you use a fair coin, the two possible outcomes, heads and tails, occur with equal probability. Therefore each flip requires 1 bit of information to transmit. Specifying the outcome of a fair coin flip provides less information (lower entropy) than specifying the outcome from a roll of a die (six equally likely outcomes).
        
Ideas from information theory have been applied in ecology. The Shannon index is a way of characterizing the species diversity present in a given community based on the number of species present (species richness) and the distribution of the number of organisms per species (species evenness). The index is increased either by having additional unique species, or by having a greater species evenness.
        
In "The concept of information in biology" (2000), John Maynard Smith discussed how ideas drawn from information theory can be applied to evolutionary biology: 1) the DNA contains information that has been programmed by natural selection; 2) this information codes for the amino acids sequence of proteins; 3) DNA and proteins carry instructions, or a program, for the development of an organism; 4) natural selection of organisms alters the information in the genome; and 5) genomic information is "meaninful" in that it generates an organism able to survive in the environment in which selection has acted. How natural selection accumulates genetic information in the genome? How can we quantify the quantity of information stored in the genome?},
author = {Shannon, C.E.},
file = {::},
journal = {The Bell System Technical Journal},
pages = {379--423},
publisher = {ACM},
title = {{A mathematical theory of communication}},
url = {http://portal.acm.org/citation.cfm?id=584093},
volume = {22},
year = {1948}
}
@article{Hutchinson1959,
annote = {In this paper Hutchinson observes two species of waterbugs living in the same pond in a cave at the Shrine of Saint Rosalia on Monte Pellegrino, Sicily, and asks, "Why are there so many kinds of animals?" Many important ecological and evolutionary concepts on the origins of biodiversity are discussed here, although some of them were introduced by others. Hutchinson extends the concept of ecological niche that he first presented as "an n-dimensional hypervolume where every point corresponds to a state of the environment which would permit a species to exist indefinitely", in a paper entitled "Concluding Remarks", in 1957 at a Cold Spring Harbor symposium.
        
The ecological implications revolve around the trophic relationships between species. He explored how much diversity can introduce a food chain in a community by estimating the fraction of energy passing through one link to the next in the chain; the limitations of the length of a food chain by the competence with other species as a consequence of the change in body size during the lifetime; and what determines the number of food chains in a community. Although all these questions are focused on food chains, Hutchinson already realized that "Biological communities do not consist of independent food chains, but of food webs, of such a kind that and individual at any level (corresponding to a link in a single chain) can use some but not all of the food provided by species in the levels below it".
        
Based on the work about community stability by MacArthur (Fluctuations of animal populations and a measure of community stability, 1955) and biological invasions by Elton (The ecology of invasions by animals and plants, 1958), he answered the original question: "We may therefore conclude that the reason why there are so many species of animals is at least partly because a complex trophic organization of a community is more stable than a simple one,..." This conclusion relies on the belief, at that time, that the number of links in a food web increased the stability of a community (MacArthur, 1955; see May, Stability and complexity in model ecosystems, 1973, to find the opposite result). In the assembly process of a community new species occupy the empty niches in the initial stages, and then the splitting of niches previously occupied by a single species allows the communities become more diverse.
        
Last, there are evolutionary implications derived from the hypothesis that communities with many species will have more probabilities to diversify because they have more "evolutionary opportunities" than communities with few species. Therefore, Hutchinson suggested that evolutionary rates depend on how complex is the community. This is a very early idea related to the current debate about whether or not there is a constant evolutionary rate.
        
      },
author = {Hutchinson, George E.},
file = {::},
journal = {The American Naturalist},
pages = {145--159},
title = {{Homage to Santa Rosalia or why are there so many kinds of animals?}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:No+Title\#0},
volume = {93},
year = {1959}
}
@book{Mayr1942,
abstract = {Ernst Mayr played a central role in the establishment of the general concept of species as metapopulation lineages, and he is the author of one of the most popular of the numerous alternative definitions of the species category. Reconciliation of incompatible species definitions and the development of a unified species concept require rejecting the interpretation of various contingent properties of metapopulation lineages, including intrinsic reproductive isolation in Mayr's definition, as necessary properties of species. On the other hand, the general concept of species as metapopulation lineages advocated by Mayr forms the foundation of this reconciliation, which follows from a corollary of that concept also advocated by Mayr: the proposition that the species is a fundamental category of biological organization. Although the general metapopulation lineage species concept and Mayr's popular species definition are commonly confused under the name "the biological species concept," they are more or less clearly distinguished in Mayr's early writings on the subject. Virtually all modern concepts and definitions of the species category, not only those that require intrinsic reproductive isolation, are to be considered biological according to the criterion proposed by Mayr. Definitions of the species category that identify a particular contingent property of metapopulation lineages (including intrinsic reproductive isolation) as a necessary property of species reduce the number of metapopulation lineages that are to be recognized taxonomically as species, but they cause conflicts among alternative species definitions and compromise the status of the species as a basic category of biological organization.},
author = {Mayr, Ernst},
booktitle = {Proceedings of the National Academy of Sciences of the United States of America},
doi = {10.1073/pnas.0502030102},
file = {::},
issn = {0027-8424},
keywords = {Animals,Biological,Biological Evolution,Classification,Classification: methods,Models,Species Specificity},
month = may,
pmid = {15851674},
publisher = {Harvard University Press},
title = {{Systematics and the origin of species}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1131873\&tool=pmcentrez\&rendertype=abstract},
volume = {102 Suppl},
year = {1942}
}
@article{Simberloff1969a,
annote = {Daniel Simberloff and Edward Wilson tested experimentally the equilibrium theory of island biogeography introduced by MacArthur and Wilson in 1967 (The theory of island biodiversity). They sampled the artrophod faunas of six very small mangrove islands and estimated their abundances. After that, they defaunated the islands through methyl bromide fumigation. The recolonization process, mainly by aerial transport, was monitored for a year and what they found was in agreement with the predictions of the equilibrium theory of island biogreography: the number of species in each island returned approximately to the pretreatment equilibrium and there was a substantial change in composition from week to week indicating extinction.
        
After the publication of "The theory of island biogeography" many papers attempted to fill data on island communities into the equilibrium theory framework. This theory states that the number of species in an oceanic or habitat island is a dynamical equilibrium between the extinction of species already there and inmigration of new species. Before this study, there was little direct evidence that islands actually behave that way because most studies consisted on either natural and uncontrolled experiments, or demonstrations of a species-area relationship that was consistent with the equilibrium hypothesis but could be explained in other ways. There was little evidence of continuing inmigration and extinction. This was the first controlled experiment.
        
In their own words: "The colonization curves plus static observations on untreated islands indicate strongly that a dynamic equilibrium number of species exists for any island. We believe the curves are produced by colonization, involving little if any interaction, then a gradual decline as interaction becomes important, and finally, a lasting dynamical equilibrium. [...] Extinction of the earliest colonists is probably caused chiefly by such physical factors as drowning or lack of suitable breeding sites and less commonly by competition and predation".},
author = {Simberloff, Daniel S and Wilson, Edward O},
file = {::},
journal = {Ecology},
number = {2},
pages = {278--296},
title = {{Experimental zoogeography of islands: the colonization of empty islands}},
volume = {50},
year = {1969}
}
